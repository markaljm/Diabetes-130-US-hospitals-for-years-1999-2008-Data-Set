{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ryy--tgQtHhAdIi3Y9vw3HGLNWgcuolQ",
      "authorship_tag": "ABX9TyO0SfJXT5qvG3Ay3P0KshLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markaljm/Diabetes-130-US-hospitals-for-years-1999-2008-Data-Set/blob/main/Diabetes_Readmission_Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "st3R2W3PiUlD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjytXEY9U1pL"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Visualization Libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Data**"
      ],
      "metadata": {
        "id": "u5Bjy6f9ifJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"./diabetic_data.csv\")"
      ],
      "metadata": {
        "id": "s0Gd66esiJjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SsKQprBVdXud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "KGYl5VFnjMe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "VrYNaXtjjn2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data  Cleaning**"
      ],
      "metadata": {
        "id": "FuoZYoauko4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Correlation\n",
        "\n",
        "#get correlations of each features in dataset\n",
        "corrmat = data.corr()\n",
        "top_corr_features = corrmat.index\n",
        "plt.figure(figsize=(20,20))\n",
        "#plot heat map\n",
        "g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlBu\")"
      ],
      "metadata": {
        "id": "CUbjvzkrnHJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in data.columns:\n",
        "    print(i, data[data[i] == '?'].shape[0])"
      ],
      "metadata": {
        "id": "INMYyvM5SOUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['readmitted'].value_counts()"
      ],
      "metadata": {
        "id": "iR7UIjVRSU-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.barplot(x=data['readmitted'].value_counts().index,   y=data['readmitted'].value_counts())\n",
        "plt.xlabel('labels', size = 12)\n",
        "plt.ylabel('# of Readmitted', size = 12)\n",
        "plt.title('Class Distribution \\n', size = 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HupZ9xG3Sb1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Created Another label to map <30 and >30 to 1 class for better Analysis and Classification.\n",
        "data['readmitted'].unique()"
      ],
      "metadata": {
        "id": "9aOu4daDSh_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created another column and take it as 2 class problem, Label the <30 and >30 as YES and Other \"N0\" as No.\n",
        "\n",
        "def check_label(text):\n",
        "    if text == '>30' or text =='<30':\n",
        "        return 'Yes'\n",
        "    else:\n",
        "        return 'No'\n",
        "    \n",
        "data['readmitted_2'] =data['readmitted'].apply(check_label) "
      ],
      "metadata": {
        "id": "yvPuFEKTSnC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.countplot(x='readmitted_2',   data= data)\n",
        "plt.xlabel('Readmitted', size = 12)\n",
        "plt.xticks(rotation=90, size = 12)\n",
        "plt.ylabel('Count', size = 12)\n",
        "plt.title('Distribution of Readmission Class  \\n\\n', size = 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qw4oq_fjSr6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data['race'] == '?', 'race'] = 'Other'"
      ],
      "metadata": {
        "id": "eHFg2pzoS8je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.barplot(x=data['race'].value_counts().index,   y=data['race'].value_counts())\n",
        "plt.xlabel('Race', size = 12)\n",
        "plt.xticks(rotation=90, size = 12)\n",
        "plt.ylabel('Count', size = 12)\n",
        "plt.title('Distribution of Race of Patients \\n', size = 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CWm6UgRpTHy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['gender'].value_counts()"
      ],
      "metadata": {
        "id": "pkEXMGfDTQB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the \"Unknown/Invalid\" gender of the data.\n",
        "data.drop(data[data['gender'] == 'Unknown/Invalid'].index, inplace = True)"
      ],
      "metadata": {
        "id": "2ZGOQtG9TVlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.reset_index(inplace = True, drop = True)"
      ],
      "metadata": {
        "id": "b1hf3fJ3TYWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['gender'].value_counts()"
      ],
      "metadata": {
        "id": "BJc0I9UfXLY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "Nn04QLLpTcEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imputed Weight**"
      ],
      "metadata": {
        "id": "ivEeIP9lcvnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"./diabetic_data.csv\", na_values=\"?\")"
      ],
      "metadata": {
        "id": "yT63m39HVDFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into independent and dependent variables\n",
        "X = data[[\"race\", \"gender\"]]\n",
        "y = data[\"weight\"]"
      ],
      "metadata": {
        "id": "S26vL8GvTqbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping of the non-numeric values to numerical values\n",
        "weights_map = {\"[0-25)\": 10, \"[25-50)\": 37.5, \"[50-75)\": 62.5, \"[75-100)\": 87.5}"
      ],
      "metadata": {
        "id": "9ThZURebaGwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the non-numeric values with their corresponding numerical values\n",
        "y = y.map(weights_map)"
      ],
      "metadata": {
        "id": "XzoIn1iaaJ45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values in the dependent variable using the mean of the column\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "y_imputed = imputer.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "OceAcWjyaPEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply one-hot encoding to the independent variables\n",
        "ct = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"encoder\", OneHotEncoder(), [\"race\", \"gender\"])\n",
        "    ],\n",
        "    remainder=\"passthrough\"\n",
        ")\n",
        "X_encoded = ct.fit_transform(X)"
      ],
      "metadata": {
        "id": "CWOl71dWT3Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a linear regression model to predict the weights based on race and gender\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_encoded, y_imputed)"
      ],
      "metadata": {
        "id": "Zogyf6_6ZWT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to impute the missing weights\n",
        "weights_imputed = regressor.predict(X_encoded)"
      ],
      "metadata": {
        "id": "w8otiFWnZZRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the imputed weights back to the DataFrame\n",
        "data[\"weights_imputed\"] = weights_imputed.flatten()"
      ],
      "metadata": {
        "id": "RCloD9sVaeSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column to the DataFrame to record the imputation method\n",
        "data[\"imputation_method\"] = \"Weight Imputation - Linear Regression with One-Hot Encoding\"\n"
      ],
      "metadata": {
        "id": "7u8fYf1iakXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the imputed data to a new CSV file\n",
        "data.to_csv(\"imputed_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "tbEalm9haqMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a message to confirm that the imputation was successful\n",
        "print(\"Weight imputation successful. Imputed data saved to imputed_data.csv.\")"
      ],
      "metadata": {
        "id": "fM8TPutaatjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./imputed_data.csv\")"
      ],
      "metadata": {
        "id": "fDOoBjaOcMpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "J39vN8llDpkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['readmitted'].value_counts()"
      ],
      "metadata": {
        "id": "m79eVFMGQjFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.barplot(x=df['readmitted'].value_counts().index,   y=df['readmitted'].value_counts())\n",
        "plt.xlabel('labels', size = 12)\n",
        "plt.ylabel('# of Readmitted', size = 12)\n",
        "plt.title('Class Distribution \\n', size = 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dkEIqIIEeoTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['readmitted'].unique()"
      ],
      "metadata": {
        "id": "hzQcDbNZezo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created another column and take it as 2 class problem, Label the <30 and >30 as YES and Other \"N0\" as No.\n",
        "\n",
        "def check_label(text):\n",
        "    if text == '>30' or text =='<30':\n",
        "        return 'Yes'\n",
        "    else:\n",
        "        return 'No'\n",
        "    \n",
        "df['readmitted_2'] =df['readmitted'].apply(check_label) "
      ],
      "metadata": {
        "id": "R0aNP-Bte7Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.countplot(x='readmitted_2',   data= df)\n",
        "plt.xlabel('Readmitted', size = 12)\n",
        "plt.xticks(rotation=90, size = 12)\n",
        "plt.ylabel('Count', size = 12)\n",
        "plt.title('Distribution of Readmission Class  \\n\\n', size = 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I155Rx5bfAF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets drop this column. \n",
        "df.drop(columns = ['weight'], inplace = True)"
      ],
      "metadata": {
        "id": "YuJZTiyhfg_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['payer_code'].value_counts()"
      ],
      "metadata": {
        "id": "FKR78omTf1HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns =['medical_specialty'], inplace = True)"
      ],
      "metadata": {
        "id": "dlYeLOIBgMHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns = ['acetohexamide','imputation_method', 'payer_code','tolbutamide', 'troglitazone', 'tolazamide', 'examide', 'citoglipton',\n",
        "                   'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
        "                   'metformin-pioglitazone'], inplace = True)"
      ],
      "metadata": {
        "id": "2aAJE2Vsg0s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "5TMmFhlng5wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[~((df['diag_1'] == \"?\") | (df['diag_2'] == \"?\") | (df['diag_3'] == \"?\"))]"
      ],
      "metadata": {
        "id": "Ymi52_UXhGVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "tGv1A5HuiiDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transform Categorical Features"
      ],
      "metadata": {
        "id": "poaWT3vOipJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "gGVVmGfojlDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features =['race', \"weights_imputed\",'gender', 'age',\n",
        "       'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses',\n",
        "       'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide',\n",
        "       'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide',\n",
        "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin',\n",
        "       'glyburide-metformin', 'change', 'diabetesMed'] \n",
        "\n",
        "for i in categorical_features:\n",
        "    df[i] = le.fit_transform(df[i])"
      ],
      "metadata": {
        "id": "PRYSyBo1imKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "31qHdDIPj7d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform Label Columns"
      ],
      "metadata": {
        "id": "4NQRfV5PkWFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = le.fit(df['readmitted_2'])"
      ],
      "metadata": {
        "id": "lWD2kEHdkLv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['readmitted_2_encoded'] = label.transform(df['readmitted_2'])  #After Label Encoding the values assigned to class values are O:No Yes:1"
      ],
      "metadata": {
        "id": "fC7XYDi4kii-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.drop(columns= ['encounter_id', 'patient_nbr', 'readmitted','readmitted_2']) #Feature correaltion to drop"
      ],
      "metadata": {
        "id": "Q5ng-eBDlFEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "GALUHFNxliJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "xNkBU_Oqluoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split dependent and independant parameters \n",
        "X = df.drop(columns= ['readmitted_2_encoded'])\n",
        "Y = df['readmitted_2_encoded']"
      ],
      "metadata": {
        "id": "pReMx7vZmUwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "from sklearn import preprocessing\n",
        "scaled_X = preprocessing.StandardScaler().fit_transform(X)"
      ],
      "metadata": {
        "id": "wUOp2cKMo-oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_X, Y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "T5ES8CaUphnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "EhTcQomMpaPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the test set results\n",
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "xnzjOxFcqatA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model performance\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "w79XMvHvqbnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators = 450, max_depth=9, random_state=43)\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "AOU0MVgDtQFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_prediction =  rf.predict(X_test)"
      ],
      "metadata": {
        "id": "1cvA5UjRtg3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, rf_prediction, target_names= ['Not Readmitted', 'Readmitted']))"
      ],
      "metadata": {
        "id": "DOWXDiSHtnrf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}